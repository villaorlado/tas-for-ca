{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from src.thumbnails_extractor import extract_frames_every_n_seconds_dir\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "# Download the dataset\n",
    "\n",
    "# The main page link is here: https://serre-lab.clps.brown.edu/resource/breakfast-actions-dataset/\n",
    "# The corresponding download link is here: https://drive.google.com/open?id=1jgSoof1AatiDRpGY091qd4TEKF-BUt6I\n",
    "# To download from the command line\n",
    "# ```\n",
    "# pip install gdown\n",
    "# gdown https://drive.google.com/open?id=1jgSoof1AatiDRpGY091qd4TEKF-BUt6I --fuzzy \n",
    "# ```\n",
    "# If it is too suspicious to download from the random link, navigate to the main page link instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "# Decompress the dataset\n",
    "\n",
    "!tar -xzvf data/BreakfastII_15fps_qvga_sync.tar.gz -C data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "decompressed_dir = \"data/BreakfastII_15fps_qvga_sync\"\n",
    "thumbnails_base_dir = \"data/Breakfast/thumbnails\"\n",
    "groundtruth_dir = \"data/Breakfast/groundtruth\"\n",
    "sampling_fps = 1\n",
    "resolution=(320,240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "# Flatten the folder structure\n",
    "\n",
    "\n",
    "# Find all files recursively\n",
    "for filepath in glob.glob(os.path.join(decompressed_dir, \"**\", \"*\"), recursive=True):\n",
    "\tif os.path.isfile(filepath):  # Ensure it's a file\n",
    "\t\t\n",
    "\t\t# Change relative path\n",
    "\t\trelative_path = os.path.relpath(filepath, decompressed_dir)\n",
    "\t\tnew_relative_path = relative_path.replace(\"/\", \"_\")\n",
    "\t\tnew_path = os.path.join(decompressed_dir, new_relative_path)\n",
    "\t\t\n",
    "\t\tos.rename(filepath, new_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "# Extract the thumbnails\n",
    "\n",
    "# Make new folder to store \n",
    "os.makedirs(thumbnails_base_dir,exist_ok=True)\n",
    "\n",
    "# Extract thumbnails\n",
    "extract_frames_every_n_seconds_dir(videos_parent_dir = decompressed_dir,\n",
    "\t\t\t\t\t\t\t\t\tthumbnails_output_parent_dir = thumbnails_base_dir,\n",
    "\t\t\t\t\t\t\t\t\tsampling_fps=sampling_fps, \n",
    "\t\t\t\t\t\t\t\t\tthumbnails_resolution=resolution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "# Generate the groundtruth files\n",
    "\n",
    "def frame_nb_in_labels(frame_nb, labels_dict):\n",
    "\tfor label, (lower_bound, upper_bound) in labels_dict.items():\n",
    "\t\tif lower_bound <= frame_nb and frame_nb <= upper_bound:\n",
    "\t\t\treturn label \n",
    "\treturn \"NIL\"\n",
    "\n",
    "# Make the folder\n",
    "os.makedirs(groundtruth_dir,exist_ok=True)\n",
    "\n",
    "# Read the thumbnails folder first\n",
    "thumbnails_dir = f\"{thumbnails_base_dir}/thumbnails_{sampling_fps}secsPerFrame_{resolution[0]}px{resolution[1]}px\"\n",
    "video_ids = os.listdir(thumbnails_dir)\n",
    "video_ids.sort()\n",
    "\n",
    "for video_id in video_ids: \n",
    "\n",
    "\t# For each video_id, find the corresponding labels file\n",
    "\tgroundtruth_path = f\"{decompressed_dir}/{video_id}.avi.labels\"\n",
    "\n",
    "\ttry:\n",
    "\t\t# Get labels dictionary\n",
    "\t\tlabels_dict = dict()\n",
    "\t\twith open(groundtruth_path,\"r\") as file:\n",
    "\t\t\tfor line in file:\n",
    "\t\t\t\tframe_intervals, label = line.strip().split(\" \")\n",
    "\t\t\t\tframe_lower_bound, frame_upper_bound = frame_intervals.split(\"-\")\n",
    "\t\t\t\tlabels_dict[label] = (int(frame_lower_bound),int(frame_upper_bound))\n",
    "\n",
    "\t\t# Open thumbnails and loop through\n",
    "\t\tframe_files = os.listdir(f\"{thumbnails_dir}/{video_id}\")\n",
    "\t\tframe_nbs = [int(Path(file).stem) for file in frame_files]\n",
    "\t\tframe_nbs.sort()\n",
    "\n",
    "\t\t# Generate groundtruth labels\n",
    "\t\tgroundtruth_file = []\n",
    "\t\tfor frame_nb in frame_nbs:\n",
    "\t\t\tgroundtruth_file.append(frame_nb_in_labels(frame_nb, labels_dict))\n",
    "\n",
    "\t\t# Write groundtruth file\n",
    "\t\twith open(f\"{groundtruth_dir}/{video_id}.txt\",\"w\") as file:\n",
    "\t\t\tfile.writelines(f\"{item}\\n\" for item in groundtruth_file)\n",
    "\n",
    "\texcept:\n",
    "\t\tprint(f\"Label for {video_id} not avail\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "# Initiate the training\n",
    "\n",
    "from src.train_and_infer import initialise_training\n",
    "\n",
    "initialise_training(cfg_path=\"src/configs/default.yaml\",\n",
    "                    thumbnails_dir=thumbnails_dir,\n",
    "                    groundtruth_dir=groundtruth_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "# Infer using a new directory\n",
    "#\n",
    "# The performance of the model is saved in the log directory\n",
    "# log/[initiated_training_timestamp]/train_metrics.csv : contains the training metrics\n",
    "# log/[initiated_training_timestamp]/test_metrics.csv : contains the evaluation metrics\n",
    "# log/[initiated_training_timestamp]/model_weights : contains the model weights \n",
    "\n",
    "from src.train_and_infer import infer_with_new_dir\n",
    "\n",
    "infer_with_new_dir(cfg_path=\"log/2025Mar03_1414h/log_config.yaml\",\n",
    "                   model_weights_path=\"log/2025Mar03_1414h/model_weights/network_iter_29.net\",\n",
    "                   eval_output_dir=\"log/2025Mar03_1414h\",\n",
    "                   dataset_name=\"new_test\",\n",
    "                   thumbnails_dir=thumbnails_dir,\n",
    "                   groundtruth_dir=None,\n",
    "                   video_list=[\"P41_stereo_P41_friedegg_ch0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wayang_kulit_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
